{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import optim\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sim_data_generation import  StateActionTransition\n",
    "from src.envs.envs import BlackOilEnv\n",
    "\n",
    "WEIGHT, HEIGHT = 80, 40\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "with open(\"saved_results_5.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "res = []\n",
    "\n",
    "for i in data:\n",
    "    for j in i:\n",
    "        res.append(j)\n",
    "\n",
    "example_fields = [i.state for i in res]\n",
    "example_dqn = res[1]\n",
    "example_field = example_dqn.state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[1.80579588e+00, 1.56305696e+00, 3.25635336e-12, ...,\n         9.35601278e-24, 2.82256183e+00, 0.00000000e+00],\n        [1.80394850e+00, 1.55744098e+00, 2.43528046e-11, ...,\n         5.22175017e-22, 2.80954332e+00, 0.00000000e+00],\n        [1.80210807e+00, 1.55167870e+00, 1.61212636e-10, ...,\n         2.28362679e-20, 2.79629271e+00, 0.00000000e+00],\n        ...,\n        [1.77916384e+00, 1.39540629e+00, 3.59415496e-06, ...,\n         1.22040102e-11, 2.48265640e+00, 0.00000000e+00],\n        [1.77989426e+00, 1.39377292e+00, 1.01229167e-06, ...,\n         9.68349180e-13, 2.48076843e+00, 0.00000000e+00],\n        [1.78098566e+00, 1.39266113e+00, 2.45708847e-07, ...,\n         5.70606246e-14, 2.48030950e+00, 0.00000000e+00]],\n\n       [[1.80381408e+00, 1.55993263e+00, 1.32069747e-11, ...,\n         1.54102199e-22, 2.81382845e+00, 0.00000000e+00],\n        [1.80174353e+00, 1.55418424e+00, 9.87702476e-11, ...,\n         8.60044887e-21, 2.80024139e+00, 0.00000000e+00],\n        [1.79966098e+00, 1.54827478e+00, 6.53859494e-10, ...,\n         3.76113563e-19, 2.78636971e+00, 0.00000000e+00],\n        ...,\n        [1.77238075e+00, 1.39152618e+00, 1.47895453e-05, ...,\n         2.06266062e-10, 2.46631420e+00, 0.00000000e+00],\n        [1.77320722e+00, 1.39022233e+00, 4.16657992e-06, ...,\n         1.63730603e-11, 2.46515228e+00, 0.00000000e+00],\n        [1.77443008e+00, 1.38939598e+00, 1.01156765e-06, ...,\n         9.65127611e-13, 2.46538601e+00, 0.00000000e+00]],\n\n       [[1.80195787e+00, 1.55704988e+00, 4.74078710e-11, ...,\n         1.98874374e-21, 2.80573829e+00, 0.00000000e+00],\n        [1.79966312e+00, 1.55118488e+00, 3.54549658e-10, ...,\n         1.10988412e-19, 2.79161022e+00, 0.00000000e+00],\n        [1.79733511e+00, 1.54514422e+00, 2.34715798e-09, ...,\n         4.85360050e-18, 2.77714197e+00, 0.00000000e+00],\n        ...,\n        [1.76538105e+00, 1.38842712e+00, 5.24602486e-05, ...,\n         2.58988738e-09, 2.45110291e+00, 0.00000000e+00],\n        [1.76632515e+00, 1.38746352e+00, 1.47833805e-05, ...,\n         2.05664228e-10, 2.45071171e+00, 0.00000000e+00],\n        [1.76770528e+00, 1.38691968e+00, 3.58993923e-06, ...,\n         1.21272136e-11, 2.45166524e+00, 0.00000000e+00]],\n\n       ...,\n\n       [[1.84109583e+00, 1.57100346e+00, 1.35370307e-17, ...,\n         1.85349738e-34, 2.89236793e+00, 0.00000000e+00],\n        [1.83926373e+00, 1.56990776e+00, 1.14358218e-16, ...,\n         1.32261588e-32, 2.88747440e+00, 0.00000000e+00],\n        [1.83734208e+00, 1.56882679e+00, 8.65908751e-16, ...,\n         7.58239907e-31, 2.88247147e+00, 0.00000000e+00],\n        ...,\n        [1.78009015e+00, 1.47220144e+00, 1.79432164e-05, ...,\n         2.76986620e-10, 2.62065129e+00, 0.00000000e+00],\n        [1.78212187e+00, 1.46980760e+00, 4.20114351e-06, ...,\n         1.51789706e-11, 2.61937627e+00, 0.00000000e+00],\n        [1.78409149e+00, 1.46748271e+00, 8.62610261e-07, ...,\n         6.39742023e-13, 2.61812343e+00, 0.00000000e+00]],\n\n       [[1.84216653e+00, 1.57154833e+00, 1.88485237e-18, ...,\n         3.60013493e-36, 2.89505374e+00, 0.00000000e+00],\n        [1.84030605e+00, 1.57051979e+00, 1.59246393e-17, ...,\n         2.56922187e-34, 2.89023707e+00, 0.00000000e+00],\n        [1.83835177e+00, 1.56950169e+00, 1.20593609e-16, ...,\n         1.47303818e-32, 2.88529620e+00, 0.00000000e+00],\n        ...,\n        [1.78033904e+00, 1.47184874e+00, 7.46191433e-06, ...,\n         4.77830294e-11, 2.62038976e+00, 0.00000000e+00],\n        [1.78258400e+00, 1.46947934e+00, 1.78485898e-06, ...,\n         2.73316092e-12, 2.61947036e+00, 0.00000000e+00],\n        [1.78474460e+00, 1.46718539e+00, 3.74101444e-07, ...,\n         1.20042326e-13, 2.61855120e+00, 0.00000000e+00]],\n\n       [[1.84319530e+00, 1.57202945e+00, 2.35241595e-19, ...,\n         5.61762710e-38, 2.89755729e+00, 0.00000000e+00],\n        [1.84130614e+00, 1.57106351e+00, 1.98771078e-18, ...,\n         4.00934419e-36, 2.89280889e+00, 0.00000000e+00],\n        [1.83931941e+00, 1.57010416e+00, 1.50541410e-17, ...,\n         2.29890710e-34, 2.88792305e+00, 0.00000000e+00],\n        ...,\n        [1.78049835e+00, 1.47139966e+00, 2.81205253e-06, ...,\n         6.76897655e-12, 2.61982467e+00, 0.00000000e+00],\n        [1.78293003e+00, 1.46905588e+00, 6.83597352e-07, ...,\n         3.99940901e-13, 2.61922385e+00, 0.00000000e+00],\n        [1.78526191e+00, 1.46679261e+00, 1.45681077e-07, ...,\n         1.81605854e-14, 2.61860896e+00, 0.00000000e+00]]])"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_field"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "263692"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import unet_model\n",
    "unet_module = importlib.reload(unet_model)\n",
    "\n",
    "model = unet_model.UNet2()\n",
    "model.to_cuda()\n",
    "\n",
    "import numpy as np\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "def create_new_model(ModelClass: unet_model.UNet2):\n",
    "    model = ModelClass()\n",
    "    target_model = ModelClass()\n",
    "\n",
    "    #Загружаем модель на устройство, определенное в самом начале (GPU или CPU)\n",
    "    model.to_cuda()\n",
    "    target_model.to_cuda()\n",
    "\n",
    "    #Сразу зададим оптимизатор, с помощью которого будем обновлять веса модели\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "    return model, target_model, optimizer\n",
    "\n",
    "\n",
    "def run_model(state, model):\n",
    "    model_input = torch.FloatTensor(state).to(device)\n",
    "    model_input = model_input.permute(0, 3, 1, 2)\n",
    "    model_output = model(model_input)\n",
    "    model_output = torch.flatten(model_output, start_dim=1)\n",
    "    return model_output\n",
    "\n",
    "\n",
    "def select_action(state, model, epsilon=0.05):\n",
    "    if random.random() < epsilon:\n",
    "        return [(random.randint(0, WEIGHT-1), random.randint(0, HEIGHT-1))]\n",
    "    actions_indexes = run_model(state, model).cpu().detach().numpy().argmax(1)\n",
    "\n",
    "    actions = []\n",
    "    for index in actions_indexes:\n",
    "        x = index // WEIGHT\n",
    "        y = index % HEIGHT\n",
    "        actions.append((x, y))\n",
    "\n",
    "    return actions\n",
    "\n",
    "def get_max_q(state, model):\n",
    "    model_output = run_model(state, model)\n",
    "\n",
    "    # находим максимальное значение - это и будет q функция\n",
    "    return model_output.max(1).values.view(-1)    # [BATCH_SIZE]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "input_example = np.stack([example_field, example_field])\n",
    "input_example = example_field[np.newaxis, ...]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "[(1, 3)]"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_action(input_example, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([3.8901], device='cuda:0', grad_fn=<ViewBackward0>)"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max_q(input_example, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "gamma = 0.99\n",
    "def fit(batch, model, target_model, optimizer):\n",
    "    state, action, reward, next_state, done = batch\n",
    "\n",
    "    # преобразуем внутри функций\n",
    "    # state = torch.tensor(state).to(device).float()\n",
    "    # next_state = torch.tensor(next_state).to(device).float()\n",
    "\n",
    "    state = np.array(state)\n",
    "    next_state = np.array(next_state)\n",
    "    reward = torch.tensor(reward).to(device).float()\n",
    "    action = torch.tensor(action).to(device)\n",
    "    done = torch.tensor(done).to(device)\n",
    "\n",
    "    # Считаем то, какие значения должна выдавать наша сеть\n",
    "    with torch.no_grad():\n",
    "        # Выбираем максимальное из значений Q-function для следующего состояния\n",
    "        target_q = get_max_q(next_state, target_model)\n",
    "        target_q[done] = 0\n",
    "\n",
    "    target_q = reward + target_q * gamma\n",
    "\n",
    "\n",
    "    flatten_index = torch.LongTensor([i[1] * HEIGHT + i[0] for i in action]).to(device)\n",
    "    flatten_index = torch.unsqueeze(flatten_index, -1)\n",
    "\n",
    "    q = run_model(state, model).gather(1, flatten_index)\n",
    "\n",
    "    loss = F.mse_loss(q, target_q.unsqueeze(1))\n",
    "\n",
    "    # Очищаем текущие градиенты внутри сети\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Применяем обратное распространение ошибки\n",
    "    loss.backward()\n",
    "\n",
    "    # Ограничиваем значения градиента. Необходимо, чтобы обновления не были слишком большими\n",
    "    for param in model.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "\n",
    "    # Делаем шаг оптимизации\n",
    "    optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, element: StateActionTransition):\n",
    "        \"\"\"Сохраняет элемент в циклический буфер\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = element\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Возвращает случайную выборку указанного размера\"\"\"\n",
    "        return list(zip(*random.sample(self.memory, batch_size)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "def make_reward_number(reward) -> float:\n",
    "    if not isinstance(reward, (float, np.float_)):\n",
    "        return reward[0]\n",
    "    return reward"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "[(3, 2, 1), (5, 3, 2), (6, 4, 3)]"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem = Memory(10)\n",
    "mem.push([1, 2, 3])\n",
    "mem.push([2, 3, 4])\n",
    "mem.push([3, 5, 6])\n",
    "mem.sample(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "sampled_batch = None\n",
    "\n",
    "def train(env: BlackOilEnv):\n",
    "    global sampled_batch\n",
    "\n",
    "    #Количество обновлений model между обновлениями target model\n",
    "    target_update = 100\n",
    "\n",
    "    #Размер одного батча, который на вход принимает модель\n",
    "    batch_size = 64\n",
    "\n",
    "    #Количество шагов среды\n",
    "    max_steps = 5000\n",
    "\n",
    "    #Границы коэффициента exploration\n",
    "    epsilon = 0.25\n",
    "\n",
    "    #Создаем модель и буфер\n",
    "    memory = Memory(2000)\n",
    "    model, target_model, optimizer = create_new_model(unet_model.UNet2)\n",
    "    rewards_by_target_updates = []\n",
    "\n",
    "    env.reset()\n",
    "    for step in tqdm(range(max_steps)):\n",
    "        state = env.observation\n",
    "\n",
    "        #Делаем шаг в среде\n",
    "\n",
    "        model_input = state[np.newaxis, ...]        # добавляем размерность батча\n",
    "\n",
    "        action = select_action(model_input, model, epsilon)[0]\n",
    "\n",
    "        new_state, reward, done = env.step(action)\n",
    "        reward = make_reward_number(reward)\n",
    "\n",
    "        #Запоминаем опыт и, если нужно, перезапускаем среду\n",
    "        memory.push((state, action, reward, new_state, done))\n",
    "        if done:\n",
    "              env.reset()\n",
    "\n",
    "        #Градиентный спуск\n",
    "        if step > batch_size:\n",
    "            sampled_batch = memory.sample(batch_size)\n",
    "            fit(sampled_batch, model, target_model, optimizer)\n",
    "\n",
    "        if (step+1) % target_update == 0:\n",
    "            target_model = copy.deepcopy(model)\n",
    "\n",
    "            #Exploitation\n",
    "            state = env.reset()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "            while not done:\n",
    "                model_input = state[np.newaxis, ...]        # добавляем размерность батча\n",
    "\n",
    "                action = select_action(model_input, target_model, epsilon=0)\n",
    "\n",
    "                state, reward, done = env.step(action)\n",
    "                reward = make_reward_number(reward)\n",
    "                total_reward += reward\n",
    "            done = False\n",
    "            state = env.reset()\n",
    "            print(f\"Testing... Get reward: {total_reward}\")\n",
    "            rewards_by_target_updates.append(total_reward)\n",
    "\n",
    "    return rewards_by_target_updates"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "from src.envs.envs import BlackOilEnv\n",
    "env = BlackOilEnv(days=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 25/5000 [02:25<7:45:31,  5.61s/it]"
     ]
    }
   ],
   "source": [
    "train(env)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "3960"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "49 * WEIGHT + HEIGHT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.6131,  0.9447, -0.7776,  ..., -0.7172, -2.0972, -3.4451],\n        [-0.6149,  0.9476, -0.7789,  ..., -0.7172, -2.0973, -3.4451]],\n       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)"
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([4358,  198], device='cuda:0')"
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2])"
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3200])"
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "outputs": [],
   "source": [
    "tmp2 ="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, obj)\u001B[0m\n\u001B[0;32m    700\u001B[0m                 \u001B[0mtype_pprinters\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtype_printers\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    701\u001B[0m                 deferred_pprinters=self.deferred_printers)\n\u001B[1;32m--> 702\u001B[1;33m             \u001B[0mprinter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpretty\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    703\u001B[0m             \u001B[0mprinter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflush\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    704\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mstream\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgetvalue\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001B[0m in \u001B[0;36mpretty\u001B[1;34m(self, obj)\u001B[0m\n\u001B[0;32m    392\u001B[0m                         \u001B[1;32mif\u001B[0m \u001B[0mcls\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    393\u001B[0m                                 \u001B[1;32mand\u001B[0m \u001B[0mcallable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcls\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__dict__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'__repr__'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 394\u001B[1;33m                             \u001B[1;32mreturn\u001B[0m \u001B[0m_repr_pprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcycle\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    395\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    396\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0m_default_pprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcycle\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001B[0m in \u001B[0;36m_repr_pprint\u001B[1;34m(obj, p, cycle)\u001B[0m\n\u001B[0;32m    698\u001B[0m     \u001B[1;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    699\u001B[0m     \u001B[1;31m# Find newlines and replace them with p.break_()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 700\u001B[1;33m     \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrepr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    701\u001B[0m     \u001B[0mlines\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moutput\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplitlines\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    702\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgroup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor.py\u001B[0m in \u001B[0;36m__repr__\u001B[1;34m(self, tensor_contents)\u001B[0m\n\u001B[0;32m    425\u001B[0m             )\n\u001B[0;32m    426\u001B[0m         \u001B[1;31m# All strings are unicode in Python 3.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 427\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_tensor_str\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_str\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensor_contents\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtensor_contents\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    428\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    429\u001B[0m     def backward(\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor_str.py\u001B[0m in \u001B[0;36m_str\u001B[1;34m(self, tensor_contents)\u001B[0m\n\u001B[0;32m    635\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    636\u001B[0m         \u001B[0mguard\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_DisableFuncTorch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 637\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_str_intern\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensor_contents\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtensor_contents\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor_str.py\u001B[0m in \u001B[0;36m_str_intern\u001B[1;34m(inp, tensor_contents)\u001B[0m\n\u001B[0;32m    566\u001B[0m                         \u001B[0mtensor_str\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_tensor_str\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_dense\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindent\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    567\u001B[0m                     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 568\u001B[1;33m                         \u001B[0mtensor_str\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_tensor_str\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindent\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    569\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    570\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayout\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrided\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor_str.py\u001B[0m in \u001B[0;36m_tensor_str\u001B[1;34m(self, indent)\u001B[0m\n\u001B[0;32m    326\u001B[0m         )\n\u001B[0;32m    327\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 328\u001B[1;33m         \u001B[0mformatter\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_Formatter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_summarized_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0msummarize\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    329\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0m_tensor_str_with_formatter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msummarize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mformatter\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    330\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor_str.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, tensor)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    114\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 115\u001B[1;33m             nonzero_finite_vals = torch.masked_select(\n\u001B[0m\u001B[0;32m    116\u001B[0m                 \u001B[0mtensor_view\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misfinite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor_view\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m&\u001B[0m \u001B[0mtensor_view\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mne\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    117\u001B[0m             )\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "tmp.gather(0, tmp2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3200])"
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.2551, -0.2551, -0.4403,  ..., -1.5179, -0.0023, -0.5512],\n        [-0.2551, -0.2551, -0.4403,  ..., -1.5179, -0.0023, -0.5512]],\n       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)"
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 3, 27],\n        [ 3, 27]], device='cuda:0')"
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3200])"
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 1, 40, 80])"
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[47,  2],\n        [74,  2]], device='cuda:0')"
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp.ga"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    ".gather(1, action.unsqueeze(1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "data": {
      "text/plain": "[(array([[[1.70479845e+00, 1.44145642e+00, 1.49586320e-13, ...,\n           2.06077189e-26, 2.45739268e+00, 0.00000000e+00],\n          [1.69915830e+00, 1.43821367e+00, 7.21193420e-13, ...,\n           4.78113715e-25, 2.44375270e+00, 0.00000000e+00],\n          [1.69374213e+00, 1.43540000e+00, 2.99446835e-12, ...,\n           8.23033150e-24, 2.43119745e+00, 0.00000000e+00],\n          ...,\n          [1.52183354e+00, 1.67589795e+00, 2.46495097e-16, ...,\n           4.71720555e-32, 2.55043771e+00, 0.00000000e+00],\n          [1.52151019e+00, 1.69245141e+00, 8.47813235e-17, ...,\n           5.54770486e-33, 2.57508207e+00, 0.00000000e+00],\n          [1.52125012e+00, 1.70843928e+00, 2.56838963e-17, ...,\n           5.06255724e-34, 2.59896346e+00, 0.00000000e+00]],\n  \n         [[1.70209903e+00, 1.44059180e+00, 1.62220348e-12, ...,\n           2.41584525e-24, 2.45202990e+00, 0.00000000e+00],\n          [1.69622813e+00, 1.43725424e+00, 7.82131066e-12, ...,\n           5.60464293e-23, 2.43791106e+00, 0.00000000e+00],\n          [1.69059263e+00, 1.43436389e+00, 3.24757335e-11, ...,\n           9.64745044e-22, 2.42492502e+00, 0.00000000e+00],\n          ...,\n          [1.52138106e+00, 1.68009840e+00, 4.00660940e-15, ...,\n           1.24553023e-29, 2.55606988e+00, 0.00000000e+00],\n          [1.52106633e+00, 1.69680582e+00, 1.37805890e-15, ...,\n           1.46472538e-30, 2.58095421e+00, 0.00000000e+00],\n          [1.52082504e+00, 1.71290725e+00, 4.17463509e-16, ...,\n           1.33651802e-31, 2.60503224e+00, 0.00000000e+00]],\n  \n         [[1.69919314e+00, 1.43950739e+00, 1.51589683e-11, ...,\n           2.10224737e-22, 2.44600109e+00, 0.00000000e+00],\n          [1.69307535e+00, 1.43605483e+00, 7.30911115e-11, ...,\n           4.87686298e-21, 2.43134904e+00, 0.00000000e+00],\n          [1.68720317e+00, 1.43306465e+00, 3.03503518e-10, ...,\n           8.39434157e-20, 2.41787122e+00, 0.00000000e+00],\n          ...,\n          [1.52081643e+00, 1.68449423e+00, 5.73908648e-14, ...,\n           2.55347415e-27, 2.56180650e+00, 0.00000000e+00],\n          [1.52051922e+00, 1.70133200e+00, 1.97387653e-14, ...,\n           3.00254321e-28, 2.58690799e+00, 0.00000000e+00],\n          [1.52030572e+00, 1.71752297e+00, 5.97927864e-15, ...,\n           2.73938615e-29, 2.61115999e+00, 0.00000000e+00]],\n  \n         ...,\n  \n         [[1.75235524e+00, 1.53461606e+00, 4.08773690e-17, ...,\n           1.56105226e-33, 2.68919249e+00, 0.00000000e+00],\n          [1.74871364e+00, 1.53313967e+00, 2.58895700e-16, ...,\n           6.24713811e-32, 2.68102226e+00, 0.00000000e+00],\n          [1.74537467e+00, 1.53217403e+00, 2.57001274e-15, ...,\n           6.14453711e-30, 2.67421774e+00, 0.00000000e+00],\n          ...,\n          [1.48653675e+00, 1.85302736e+00, 2.05144027e-07, ...,\n           3.21708275e-14, 2.75459327e+00, 0.00000000e+00],\n          [1.48966955e+00, 1.86389689e+00, 7.04611994e-08, ...,\n           3.77939749e-15, 2.77659044e+00, 0.00000000e+00],\n          [1.49263491e+00, 1.87416195e+00, 2.13143004e-08, ...,\n           3.44445856e-16, 2.79743954e+00, 0.00000000e+00]],\n  \n         [[1.75607735e+00, 1.54107424e+00, 3.70189148e-18, ...,\n           1.28675271e-35, 2.70624558e+00, 0.00000000e+00],\n          [1.75265265e+00, 1.53973788e+00, 4.28207707e-17, ...,\n           1.71777039e-33, 2.69862567e+00, 0.00000000e+00],\n          [1.74950971e+00, 1.53889490e+00, 4.37822500e-16, ...,\n           1.79249808e-31, 2.69231156e+00, 0.00000000e+00],\n          ...,\n          [1.48786985e+00, 1.85993432e+00, 3.47290806e-08, ...,\n           9.24989549e-16, 2.76734020e+00, 0.00000000e+00],\n          [1.49081698e+00, 1.87018164e+00, 1.19309694e-08, ...,\n           1.08693757e-16, 2.78809854e+00, 0.00000000e+00],\n          [1.49362170e+00, 1.87989492e+00, 3.60981081e-09, ...,\n           9.90845105e-18, 2.80785184e+00, 0.00000000e+00]],\n  \n         [[1.75933976e+00, 1.54752601e+00, 5.28970376e-19, ...,\n           2.64023503e-37, 2.72262405e+00, 1.00000000e+00],\n          [1.75609624e+00, 1.54632273e+00, 6.28256464e-18, ...,\n           3.71605481e-35, 2.71549153e+00, 0.00000000e+00],\n          [1.75311185e+00, 1.54559412e+00, 6.60679422e-17, ...,\n           4.10209959e-33, 2.70959935e+00, 0.00000000e+00],\n          ...,\n          [1.48929569e+00, 1.86700607e+00, 5.18010317e-09, ...,\n           2.06451233e-17, 2.78052410e+00, 0.00000000e+00],\n          [1.49205357e+00, 1.87662527e+00, 1.77991532e-09, ...,\n           2.42646268e-18, 2.80002543e+00, 0.00000000e+00],\n          [1.49469230e+00, 1.88577606e+00, 5.38623501e-10, ...,\n           2.21239404e-19, 2.81865496e+00, 0.00000000e+00]]]),\n  array([[[1.70479845e+00, 1.44145642e+00, 1.49586320e-13, ...,\n           2.06077189e-26, 2.45739268e+00, 0.00000000e+00],\n          [1.69915830e+00, 1.43821367e+00, 7.21193420e-13, ...,\n           4.78113715e-25, 2.44375270e+00, 0.00000000e+00],\n          [1.69374213e+00, 1.43540000e+00, 2.99446835e-12, ...,\n           8.23033150e-24, 2.43119745e+00, 0.00000000e+00],\n          ...,\n          [1.52183354e+00, 1.67589795e+00, 2.46495097e-16, ...,\n           4.71720555e-32, 2.55043771e+00, 0.00000000e+00],\n          [1.52151019e+00, 1.69245141e+00, 8.47813235e-17, ...,\n           5.54770486e-33, 2.57508207e+00, 0.00000000e+00],\n          [1.52125012e+00, 1.70843928e+00, 2.56838963e-17, ...,\n           5.06255724e-34, 2.59896346e+00, 0.00000000e+00]],\n  \n         [[1.70209903e+00, 1.44059180e+00, 1.62220348e-12, ...,\n           2.41584525e-24, 2.45202990e+00, 0.00000000e+00],\n          [1.69622813e+00, 1.43725424e+00, 7.82131066e-12, ...,\n           5.60464293e-23, 2.43791106e+00, 0.00000000e+00],\n          [1.69059263e+00, 1.43436389e+00, 3.24757335e-11, ...,\n           9.64745044e-22, 2.42492502e+00, 0.00000000e+00],\n          ...,\n          [1.52138106e+00, 1.68009840e+00, 4.00660940e-15, ...,\n           1.24553023e-29, 2.55606988e+00, 0.00000000e+00],\n          [1.52106633e+00, 1.69680582e+00, 1.37805890e-15, ...,\n           1.46472538e-30, 2.58095421e+00, 0.00000000e+00],\n          [1.52082504e+00, 1.71290725e+00, 4.17463509e-16, ...,\n           1.33651802e-31, 2.60503224e+00, 0.00000000e+00]],\n  \n         [[1.69919314e+00, 1.43950739e+00, 1.51589683e-11, ...,\n           2.10224737e-22, 2.44600109e+00, 0.00000000e+00],\n          [1.69307535e+00, 1.43605483e+00, 7.30911115e-11, ...,\n           4.87686298e-21, 2.43134904e+00, 0.00000000e+00],\n          [1.68720317e+00, 1.43306465e+00, 3.03503518e-10, ...,\n           8.39434157e-20, 2.41787122e+00, 0.00000000e+00],\n          ...,\n          [1.52081643e+00, 1.68449423e+00, 5.73908648e-14, ...,\n           2.55347415e-27, 2.56180650e+00, 0.00000000e+00],\n          [1.52051922e+00, 1.70133200e+00, 1.97387653e-14, ...,\n           3.00254321e-28, 2.58690799e+00, 0.00000000e+00],\n          [1.52030572e+00, 1.71752297e+00, 5.97927864e-15, ...,\n           2.73938615e-29, 2.61115999e+00, 0.00000000e+00]],\n  \n         ...,\n  \n         [[1.75235524e+00, 1.53461606e+00, 4.08773690e-17, ...,\n           1.56105226e-33, 2.68919249e+00, 0.00000000e+00],\n          [1.74871364e+00, 1.53313967e+00, 2.58895700e-16, ...,\n           6.24713811e-32, 2.68102226e+00, 0.00000000e+00],\n          [1.74537467e+00, 1.53217403e+00, 2.57001274e-15, ...,\n           6.14453711e-30, 2.67421774e+00, 0.00000000e+00],\n          ...,\n          [1.48653675e+00, 1.85302736e+00, 2.05144027e-07, ...,\n           3.21708275e-14, 2.75459327e+00, 0.00000000e+00],\n          [1.48966955e+00, 1.86389689e+00, 7.04611994e-08, ...,\n           3.77939749e-15, 2.77659044e+00, 0.00000000e+00],\n          [1.49263491e+00, 1.87416195e+00, 2.13143004e-08, ...,\n           3.44445856e-16, 2.79743954e+00, 0.00000000e+00]],\n  \n         [[1.75607735e+00, 1.54107424e+00, 3.70189148e-18, ...,\n           1.28675271e-35, 2.70624558e+00, 0.00000000e+00],\n          [1.75265265e+00, 1.53973788e+00, 4.28207707e-17, ...,\n           1.71777039e-33, 2.69862567e+00, 0.00000000e+00],\n          [1.74950971e+00, 1.53889490e+00, 4.37822500e-16, ...,\n           1.79249808e-31, 2.69231156e+00, 0.00000000e+00],\n          ...,\n          [1.48786985e+00, 1.85993432e+00, 3.47290806e-08, ...,\n           9.24989549e-16, 2.76734020e+00, 0.00000000e+00],\n          [1.49081698e+00, 1.87018164e+00, 1.19309694e-08, ...,\n           1.08693757e-16, 2.78809854e+00, 0.00000000e+00],\n          [1.49362170e+00, 1.87989492e+00, 3.60981081e-09, ...,\n           9.90845105e-18, 2.80785184e+00, 0.00000000e+00]],\n  \n         [[1.75933976e+00, 1.54752601e+00, 5.28970376e-19, ...,\n           2.64023503e-37, 2.72262405e+00, 1.00000000e+00],\n          [1.75609624e+00, 1.54632273e+00, 6.28256464e-18, ...,\n           3.71605481e-35, 2.71549153e+00, 0.00000000e+00],\n          [1.75311185e+00, 1.54559412e+00, 6.60679422e-17, ...,\n           4.10209959e-33, 2.70959935e+00, 0.00000000e+00],\n          ...,\n          [1.48929569e+00, 1.86700607e+00, 5.18010317e-09, ...,\n           2.06451233e-17, 2.78052410e+00, 0.00000000e+00],\n          [1.49205357e+00, 1.87662527e+00, 1.77991532e-09, ...,\n           2.42646268e-18, 2.80002543e+00, 0.00000000e+00],\n          [1.49469230e+00, 1.88577606e+00, 5.38623501e-10, ...,\n           2.21239404e-19, 2.81865496e+00, 0.00000000e+00]]])),\n ((0, 39), (0, 39)),\n (0.0, 0.0),\n (array([[[1.70479845e+00, 1.44145642e+00, 1.49586320e-13, ...,\n           2.06077189e-26, 2.45739268e+00, 0.00000000e+00],\n          [1.69915830e+00, 1.43821367e+00, 7.21193420e-13, ...,\n           4.78113715e-25, 2.44375270e+00, 0.00000000e+00],\n          [1.69374213e+00, 1.43540000e+00, 2.99446835e-12, ...,\n           8.23033150e-24, 2.43119745e+00, 0.00000000e+00],\n          ...,\n          [1.52183354e+00, 1.67589795e+00, 2.46495097e-16, ...,\n           4.71720555e-32, 2.55043771e+00, 0.00000000e+00],\n          [1.52151019e+00, 1.69245141e+00, 8.47813235e-17, ...,\n           5.54770486e-33, 2.57508207e+00, 0.00000000e+00],\n          [1.52125012e+00, 1.70843928e+00, 2.56838963e-17, ...,\n           5.06255724e-34, 2.59896346e+00, 0.00000000e+00]],\n  \n         [[1.70209903e+00, 1.44059180e+00, 1.62220348e-12, ...,\n           2.41584525e-24, 2.45202990e+00, 0.00000000e+00],\n          [1.69622813e+00, 1.43725424e+00, 7.82131066e-12, ...,\n           5.60464293e-23, 2.43791106e+00, 0.00000000e+00],\n          [1.69059263e+00, 1.43436389e+00, 3.24757335e-11, ...,\n           9.64745044e-22, 2.42492502e+00, 0.00000000e+00],\n          ...,\n          [1.52138106e+00, 1.68009840e+00, 4.00660940e-15, ...,\n           1.24553023e-29, 2.55606988e+00, 0.00000000e+00],\n          [1.52106633e+00, 1.69680582e+00, 1.37805890e-15, ...,\n           1.46472538e-30, 2.58095421e+00, 0.00000000e+00],\n          [1.52082504e+00, 1.71290725e+00, 4.17463509e-16, ...,\n           1.33651802e-31, 2.60503224e+00, 0.00000000e+00]],\n  \n         [[1.69919314e+00, 1.43950739e+00, 1.51589683e-11, ...,\n           2.10224737e-22, 2.44600109e+00, 0.00000000e+00],\n          [1.69307535e+00, 1.43605483e+00, 7.30911115e-11, ...,\n           4.87686298e-21, 2.43134904e+00, 0.00000000e+00],\n          [1.68720317e+00, 1.43306465e+00, 3.03503518e-10, ...,\n           8.39434157e-20, 2.41787122e+00, 0.00000000e+00],\n          ...,\n          [1.52081643e+00, 1.68449423e+00, 5.73908648e-14, ...,\n           2.55347415e-27, 2.56180650e+00, 0.00000000e+00],\n          [1.52051922e+00, 1.70133200e+00, 1.97387653e-14, ...,\n           3.00254321e-28, 2.58690799e+00, 0.00000000e+00],\n          [1.52030572e+00, 1.71752297e+00, 5.97927864e-15, ...,\n           2.73938615e-29, 2.61115999e+00, 0.00000000e+00]],\n  \n         ...,\n  \n         [[1.75235524e+00, 1.53461606e+00, 4.08773690e-17, ...,\n           1.56105226e-33, 2.68919249e+00, 0.00000000e+00],\n          [1.74871364e+00, 1.53313967e+00, 2.58895700e-16, ...,\n           6.24713811e-32, 2.68102226e+00, 0.00000000e+00],\n          [1.74537467e+00, 1.53217403e+00, 2.57001274e-15, ...,\n           6.14453711e-30, 2.67421774e+00, 0.00000000e+00],\n          ...,\n          [1.48653675e+00, 1.85302736e+00, 2.05144027e-07, ...,\n           3.21708275e-14, 2.75459327e+00, 0.00000000e+00],\n          [1.48966955e+00, 1.86389689e+00, 7.04611994e-08, ...,\n           3.77939749e-15, 2.77659044e+00, 0.00000000e+00],\n          [1.49263491e+00, 1.87416195e+00, 2.13143004e-08, ...,\n           3.44445856e-16, 2.79743954e+00, 0.00000000e+00]],\n  \n         [[1.75607735e+00, 1.54107424e+00, 3.70189148e-18, ...,\n           1.28675271e-35, 2.70624558e+00, 0.00000000e+00],\n          [1.75265265e+00, 1.53973788e+00, 4.28207707e-17, ...,\n           1.71777039e-33, 2.69862567e+00, 0.00000000e+00],\n          [1.74950971e+00, 1.53889490e+00, 4.37822500e-16, ...,\n           1.79249808e-31, 2.69231156e+00, 0.00000000e+00],\n          ...,\n          [1.48786985e+00, 1.85993432e+00, 3.47290806e-08, ...,\n           9.24989549e-16, 2.76734020e+00, 0.00000000e+00],\n          [1.49081698e+00, 1.87018164e+00, 1.19309694e-08, ...,\n           1.08693757e-16, 2.78809854e+00, 0.00000000e+00],\n          [1.49362170e+00, 1.87989492e+00, 3.60981081e-09, ...,\n           9.90845105e-18, 2.80785184e+00, 0.00000000e+00]],\n  \n         [[1.75933976e+00, 1.54752601e+00, 5.28970376e-19, ...,\n           2.64023503e-37, 2.72262405e+00, 1.00000000e+00],\n          [1.75609624e+00, 1.54632273e+00, 6.28256464e-18, ...,\n           3.71605481e-35, 2.71549153e+00, 0.00000000e+00],\n          [1.75311185e+00, 1.54559412e+00, 6.60679422e-17, ...,\n           4.10209959e-33, 2.70959935e+00, 0.00000000e+00],\n          ...,\n          [1.48929569e+00, 1.86700607e+00, 5.18010317e-09, ...,\n           2.06451233e-17, 2.78052410e+00, 0.00000000e+00],\n          [1.49205357e+00, 1.87662527e+00, 1.77991532e-09, ...,\n           2.42646268e-18, 2.80002543e+00, 0.00000000e+00],\n          [1.49469230e+00, 1.88577606e+00, 5.38623501e-10, ...,\n           2.21239404e-19, 2.81865496e+00, 0.00000000e+00]]]),\n  array([[[1.70479845e+00, 1.44145642e+00, 1.49586320e-13, ...,\n           2.06077189e-26, 2.45739268e+00, 0.00000000e+00],\n          [1.69915830e+00, 1.43821367e+00, 7.21193420e-13, ...,\n           4.78113715e-25, 2.44375270e+00, 0.00000000e+00],\n          [1.69374213e+00, 1.43540000e+00, 2.99446835e-12, ...,\n           8.23033150e-24, 2.43119745e+00, 0.00000000e+00],\n          ...,\n          [1.52183354e+00, 1.67589795e+00, 2.46495097e-16, ...,\n           4.71720555e-32, 2.55043771e+00, 0.00000000e+00],\n          [1.52151019e+00, 1.69245141e+00, 8.47813235e-17, ...,\n           5.54770486e-33, 2.57508207e+00, 0.00000000e+00],\n          [1.52125012e+00, 1.70843928e+00, 2.56838963e-17, ...,\n           5.06255724e-34, 2.59896346e+00, 0.00000000e+00]],\n  \n         [[1.70209903e+00, 1.44059180e+00, 1.62220348e-12, ...,\n           2.41584525e-24, 2.45202990e+00, 0.00000000e+00],\n          [1.69622813e+00, 1.43725424e+00, 7.82131066e-12, ...,\n           5.60464293e-23, 2.43791106e+00, 0.00000000e+00],\n          [1.69059263e+00, 1.43436389e+00, 3.24757335e-11, ...,\n           9.64745044e-22, 2.42492502e+00, 0.00000000e+00],\n          ...,\n          [1.52138106e+00, 1.68009840e+00, 4.00660940e-15, ...,\n           1.24553023e-29, 2.55606988e+00, 0.00000000e+00],\n          [1.52106633e+00, 1.69680582e+00, 1.37805890e-15, ...,\n           1.46472538e-30, 2.58095421e+00, 0.00000000e+00],\n          [1.52082504e+00, 1.71290725e+00, 4.17463509e-16, ...,\n           1.33651802e-31, 2.60503224e+00, 0.00000000e+00]],\n  \n         [[1.69919314e+00, 1.43950739e+00, 1.51589683e-11, ...,\n           2.10224737e-22, 2.44600109e+00, 0.00000000e+00],\n          [1.69307535e+00, 1.43605483e+00, 7.30911115e-11, ...,\n           4.87686298e-21, 2.43134904e+00, 0.00000000e+00],\n          [1.68720317e+00, 1.43306465e+00, 3.03503518e-10, ...,\n           8.39434157e-20, 2.41787122e+00, 0.00000000e+00],\n          ...,\n          [1.52081643e+00, 1.68449423e+00, 5.73908648e-14, ...,\n           2.55347415e-27, 2.56180650e+00, 0.00000000e+00],\n          [1.52051922e+00, 1.70133200e+00, 1.97387653e-14, ...,\n           3.00254321e-28, 2.58690799e+00, 0.00000000e+00],\n          [1.52030572e+00, 1.71752297e+00, 5.97927864e-15, ...,\n           2.73938615e-29, 2.61115999e+00, 0.00000000e+00]],\n  \n         ...,\n  \n         [[1.75235524e+00, 1.53461606e+00, 4.08773690e-17, ...,\n           1.56105226e-33, 2.68919249e+00, 0.00000000e+00],\n          [1.74871364e+00, 1.53313967e+00, 2.58895700e-16, ...,\n           6.24713811e-32, 2.68102226e+00, 0.00000000e+00],\n          [1.74537467e+00, 1.53217403e+00, 2.57001274e-15, ...,\n           6.14453711e-30, 2.67421774e+00, 0.00000000e+00],\n          ...,\n          [1.48653675e+00, 1.85302736e+00, 2.05144027e-07, ...,\n           3.21708275e-14, 2.75459327e+00, 0.00000000e+00],\n          [1.48966955e+00, 1.86389689e+00, 7.04611994e-08, ...,\n           3.77939749e-15, 2.77659044e+00, 0.00000000e+00],\n          [1.49263491e+00, 1.87416195e+00, 2.13143004e-08, ...,\n           3.44445856e-16, 2.79743954e+00, 0.00000000e+00]],\n  \n         [[1.75607735e+00, 1.54107424e+00, 3.70189148e-18, ...,\n           1.28675271e-35, 2.70624558e+00, 0.00000000e+00],\n          [1.75265265e+00, 1.53973788e+00, 4.28207707e-17, ...,\n           1.71777039e-33, 2.69862567e+00, 0.00000000e+00],\n          [1.74950971e+00, 1.53889490e+00, 4.37822500e-16, ...,\n           1.79249808e-31, 2.69231156e+00, 0.00000000e+00],\n          ...,\n          [1.48786985e+00, 1.85993432e+00, 3.47290806e-08, ...,\n           9.24989549e-16, 2.76734020e+00, 0.00000000e+00],\n          [1.49081698e+00, 1.87018164e+00, 1.19309694e-08, ...,\n           1.08693757e-16, 2.78809854e+00, 0.00000000e+00],\n          [1.49362170e+00, 1.87989492e+00, 3.60981081e-09, ...,\n           9.90845105e-18, 2.80785184e+00, 0.00000000e+00]],\n  \n         [[1.75933976e+00, 1.54752601e+00, 5.28970376e-19, ...,\n           2.64023503e-37, 2.72262405e+00, 1.00000000e+00],\n          [1.75609624e+00, 1.54632273e+00, 6.28256464e-18, ...,\n           3.71605481e-35, 2.71549153e+00, 0.00000000e+00],\n          [1.75311185e+00, 1.54559412e+00, 6.60679422e-17, ...,\n           4.10209959e-33, 2.70959935e+00, 0.00000000e+00],\n          ...,\n          [1.48929569e+00, 1.86700607e+00, 5.18010317e-09, ...,\n           2.06451233e-17, 2.78052410e+00, 0.00000000e+00],\n          [1.49205357e+00, 1.87662527e+00, 1.77991532e-09, ...,\n           2.42646268e-18, 2.80002543e+00, 0.00000000e+00],\n          [1.49469230e+00, 1.88577606e+00, 5.38623501e-10, ...,\n           2.21239404e-19, 2.81865496e+00, 0.00000000e+00]]])),\n (False, False)]"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next state:  (2, 40, 80, 8)\n",
      "(2, 40, 80, 8)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_26688/1125286070.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_input\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m     \u001B[0mtarget_q\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_max_q\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_input\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m     \u001B[0mtarget_q\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mdone\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[0mtarget_q\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mreward\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mtarget_q\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mgamma\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_26688/3114057834.py\u001B[0m in \u001B[0;36mget_max_q\u001B[1;34m(state, model)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mget_max_q\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 40\u001B[1;33m     \u001B[0mmodel_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrun_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m...\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     41\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[1;31m# находим максимальное значение - это и будет q функция\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_26688/3114057834.py\u001B[0m in \u001B[0;36mrun_model\u001B[1;34m(state, model)\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[0mmodel_input\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mFloatTensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m     \u001B[0mmodel_input\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel_input\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpermute\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m     \u001B[0mmodel_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_input\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m     \u001B[0mmodel_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"cpu\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mmodel_output\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\rl_oil_production\\unet_model.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     73\u001B[0m                 \u001B[0minput_conv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mresults_pool\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 75\u001B[1;33m             \u001B[0mresults_conv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconv_down_layers\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_conv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     76\u001B[0m             \u001B[0mresults_pool\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpool_layers\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresults_conv\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\container.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    202\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    203\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 204\u001B[1;33m             \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    205\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\rl_oil_production\\unet_model.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\container.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    202\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    203\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 204\u001B[1;33m             \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    205\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    461\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    462\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 463\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    464\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    465\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    457\u001B[0m                             \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    458\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[1;32m--> 459\u001B[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[0m\u001B[0;32m    460\u001B[0m                         self.padding, self.dilation, self.groups)\n\u001B[0;32m    461\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "state, action, reward, next_state, done = sampled_batch\n",
    "\n",
    "# Загружаем батч на выбранное ранее устройство\n",
    "# [BATCH_SIZE, ...]\n",
    "\n",
    "# преобразуем внутри функций\n",
    "# state = torch.tensor(state).to(device).float()\n",
    "# next_state = torch.tensor(next_state).to(device).float()\n",
    "\n",
    "state = np.array(state)\n",
    "next_state = np.array(next_state)\n",
    "reward = torch.tensor(reward).to(device).float()\n",
    "action = torch.tensor(action).to(device)\n",
    "done = torch.tensor(done).to(device)\n",
    "\n",
    "print(\"next state: \", next_state.shape)\n",
    "# Считаем то, какие значения должна выдавать наша сеть\n",
    "# target_q = torch.zeros(reward.size()[0]).float().to(device)\n",
    "with torch.no_grad():\n",
    "    # Выбираем максимальное из значений Q-function для следующего состояния\n",
    "    model_input = next_state\n",
    "    print(model_input.shape)\n",
    "\n",
    "    target_q = get_max_q(model_input, model)\n",
    "    target_q[done] = 0\n",
    "target_q = reward + target_q * gamma"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target_q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_26688/3548122514.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtarget_q\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'target_q' is not defined"
     ]
    }
   ],
   "source": [
    "target_q.device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 5 is not equal to len(dims) = 4",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_26688/1311873780.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[1;31m# Выбираем максимальное из значений Q-function для следующего состояния\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mmodel_input\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnext_state\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnewaxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m...\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m     \u001B[0mtarget_q\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_max_q\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_input\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m     \u001B[0mtarget_q\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mdone\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[0mtarget_q\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mreward\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mtarget_q\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mgamma\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_26688/4216244125.py\u001B[0m in \u001B[0;36mget_max_q\u001B[1;34m(state, model)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mget_max_q\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 40\u001B[1;33m     \u001B[0mmodel_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrun_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m...\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     41\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[1;31m# находим максимальное значение - это и будет q функция\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_26688/4216244125.py\u001B[0m in \u001B[0;36mrun_model\u001B[1;34m(state, model)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mrun_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[0mmodel_input\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mFloatTensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m     \u001B[0mmodel_input\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel_input\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpermute\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m     \u001B[0mmodel_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_input\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m     \u001B[0mmodel_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"cpu\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 5 is not equal to len(dims) = 4"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "state, action, reward, next_state, done = sampled_batch\n",
    "\n",
    "# Загружаем батч на выбранное ранее устройство\n",
    "# [BATCH_SIZE, ...]\n",
    "\n",
    "# преобразуем внутри функций\n",
    "# state = torch.tensor(state).to(device).float()\n",
    "# next_state = torch.tensor(next_state).to(device).float()\n",
    "\n",
    "reward = torch.tensor(reward).to(device).float()\n",
    "action = torch.tensor(action).to(device)\n",
    "done = torch.tensor(done).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampled_batch[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# with torch.no_grad():\n",
    "#     # Выбираем максимальное из значений Q-function для следующего состояния\n",
    "#     model_input = next_state[np.newaxis, ...]\n",
    "#     target_q = get_max_q(model_input, target_model)\n",
    "#     target_q[done] = 0\n",
    "# target_q = reward + target_q * gamma"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}